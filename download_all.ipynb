{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import requests\n",
    "import getpass\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = input(\"E-Mail: \")\n",
    "password = getpass.getpass(\"Password: \")\n",
    "\n",
    "users = {'Username':36} #username and number of pages in \"search overview\"\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the payload\n",
    "payload = {'userCredentialsForm.userCredentials.email':email,\n",
    "          'userCredentialsForm.userCredentials.password':password,\n",
    "           '_target1':'Login'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the session\n",
    "session = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post the payload to the site to log in\n",
    "s = session.get(\"https://old.sportstracklive.com/\", data=payload)\n",
    "s = session.get(\"https://old.sportstracklive.com/signin\", data=payload)\n",
    "s = session.post(\"https://old.sportstracklive.com/signin\", data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"login.html\", 'wb') as f:\n",
    "    print(f\"Write file login.html\")\n",
    "    f.write(s.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dashboard_url = f\"http://old.sportstracklive.com/user/{list(users.keys())[0]}\"\n",
    "s = session.post(user_dashboard_url, data=payload)\n",
    "with open(\"overview.html\", 'wb') as f:\n",
    "    print(f\"Write file overview.html\")\n",
    "    f.write(s.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "for user, pages in users.items():\n",
    "    print(\"User:\", user)\n",
    "    directory = os.path.join(\"website\", user)\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    pages = range(0,pages)\n",
    "    print(\"pages:\", list(pages))\n",
    "    \n",
    "           \n",
    "    \n",
    "    urls = []\n",
    "    content = []\n",
    "    for page in pages:\n",
    "        url = f'http://old.sportstracklive.com/search?what=user:{user}&find=track&order=relevance&page={page}'\n",
    "        \n",
    "        urls.append(url)\n",
    "         \n",
    "        # Navigate to the next page and scrape the data\n",
    "        s = session.get(url)\n",
    "\n",
    "        content.append(s)\n",
    "\n",
    "        filename = f\"overview_{page}.html\"\n",
    "        path = os.path.join(directory, filename)\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            print(f\"Write file {path}\")\n",
    "            f.write(s.content)\n",
    "        \n",
    "    print(urls)\n",
    "    \n",
    "    user_data = dict(\n",
    "        urls = urls,\n",
    "        content = content\n",
    "    )\n",
    "    \n",
    "    data[user] = user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(url, directory, file_prefix):   \n",
    "    \n",
    "    s = session.get(url)\n",
    "    filename = f\"{file_prefix}.html\"\n",
    "    path = os.path.join(directory, filename)\n",
    "\n",
    "    with open(path, 'wb') as f:\n",
    "        #print(f\"Write file {path}\")\n",
    "        f.write(s.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracks(trackid, directory, file_prefix):\n",
    "    \n",
    "    exts = ['gpx'] #kml, csv possible as well\n",
    "    \n",
    "    for ext in exts:\n",
    "    \n",
    "        url = f\"http://old.sportstracklive.com/track/{ext}?id={trackid}\"\n",
    "    \n",
    "        #print(f\"Download {url}\")\n",
    "        s = session.get(url)\n",
    "        #print(\"Response:\", s.ok)\n",
    "            \n",
    "        filename = f\"{file_prefix}.{ext}.zip\"\n",
    "        path = os.path.join(directory, filename)\n",
    "\n",
    "        if s.ok:\n",
    "            with open(path, 'wb') as f:\n",
    "                #print(f\"Write file {path}\")\n",
    "                f.write(s.content)\n",
    "        else:\n",
    "            #print(f\"No {ext}-data for {filename}\")\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = dict()\n",
    "\n",
    "for user, user_data in data.items():\n",
    "    print(user)\n",
    "    directory = os.path.join(\"website\", user, \"tracks\")\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "#    user_tracks = []\n",
    "#    print(user_data['content'])\n",
    "    for page in user_data['content']:\n",
    "\n",
    "        #print(page.text)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        infos = soup.find_all(\"a\", title=\"Info\")\n",
    "\n",
    "        for info in infos:\n",
    "            link = info.get('href')\n",
    "            print(link)\n",
    "\n",
    "            sports = link.split('/')[4]\n",
    "            location = link.split('/')[5]\n",
    "            trackid = link.rsplit('/',1)[1]\n",
    "\n",
    "            #print(sports, location, trackid)\n",
    "\n",
    "\n",
    "            file_prefix = f\"{sports}-{location}-{trackid}\"\n",
    "            \n",
    "            url = \"http://old.sportstracklive.com/\" + link\n",
    "            save_html(url, directory, file_prefix)\n",
    "            save_tracks(trackid, directory, file_prefix)\n",
    "                \n",
    "                \n",
    "#    tracks[user] = user_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-Processing (unzipping and deleting)\n",
    "for user, user_data in data.items():\n",
    "    print(user)\n",
    "    directory = os.path.join(\"website\", user, \"tracks\")\n",
    "    \n",
    "    directory_delete = os.path.join(directory, \"delete\")\n",
    "    if not os.path.exists(directory_delete):\n",
    "        os.makedirs(directory_delete)\n",
    "        \n",
    "    directory_gpx = os.path.join(directory, \"routes\")\n",
    "    if not os.path.exists(directory_gpx):\n",
    "        os.makedirs(directory_gpx)\n",
    "    \n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    for f in files:\n",
    "        fp = os.path.join(directory, f)\n",
    "        \n",
    "        if fp.rsplit(\".\",1)[1] == 'zip':\n",
    "            print(\"File:\", fp)\n",
    "            b = os.path.getsize(fp)\n",
    "            print(\"Size:\", b)\n",
    "            \n",
    "            if b < 1024:\n",
    "                print(\"File too small -> delete\")\n",
    "                fp_delete = os.path.join(directory_delete, f)\n",
    "                os.rename(fp, fp_delete)\n",
    "                \n",
    "            else:\n",
    "                print(\"File size okay -> unzip\")\n",
    "                with zipfile.ZipFile(fp,\"r\") as zip_ref:\n",
    "                    zip_ref.extractall(directory_gpx)\n",
    "                    \n",
    "                print(\"File extracted -> delete\")\n",
    "                fp_delete = os.path.join(directory_delete, f)\n",
    "                os.rename(fp, fp_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sportstracklive_scraper",
   "language": "python",
   "name": "sportstracklive_scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
